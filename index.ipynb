{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bsc.edu/academics/computing/index.html'\n",
    "\n",
    "response = get(url)\n",
    "soup = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import chromedriver_autoinstaller\n",
    "import os\n",
    "import re\n",
    "from time import sleep\n",
    "\n",
    "def create_driver(headless=True):\n",
    "    driver = chromedriver_autoinstaller.install(cwd=True)\n",
    "    chrome_options = webdriver.ChromeOptions()     \n",
    "    prefs = {'download.default_directory' : os.getcwd()}\n",
    "    chrome_options.add_experimental_option('prefs', prefs)\n",
    "    if headless:\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "    driver = webdriver.Chrome(driver, \n",
    "                             chrome_options = chrome_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joel/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: use options instead of chrome_options\n"
     ]
    }
   ],
   "source": [
    "driver = create_driver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faculty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'https://www.bsc.edu/academics/'\n",
    "url = root + 'index.html'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source)\n",
    "div = soup.find_all('h2', text=re.compile('Academic Departments'))[0].parent\n",
    "a_tags = div.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "department_links = {a.text: root + a.attrs['href'] for a in a_tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Applied Computer Science': 'https://www.bsc.edu/academics/computing/index.html',\n",
       " 'Mathematics': 'https://www.bsc.edu/academics/math/index.html',\n",
       " 'Art & Art History': 'https://www.bsc.edu/academics/art/index.html',\n",
       " 'Media And Film Studies': 'https://www.bsc.edu/academics/media/index.html',\n",
       " 'Biology': 'https://www.bsc.edu/academics/biology/index.html',\n",
       " 'Music': 'https://www.bsc.edu/academics/music/index.html',\n",
       " 'Business': 'https://www.bsc.edu/academics/business/index.html',\n",
       " 'Philosophy': 'https://www.bsc.edu/academics/philosophy/index.html',\n",
       " 'Chemistry': 'https://www.bsc.edu/academics/chem-phy/index.html',\n",
       " 'Political Science': 'https://www.bsc.edu/academics/polysci-econ-soc/polisci.html',\n",
       " 'Classics': 'https://www.bsc.edu/academics/greek-roman/index.html',\n",
       " 'Psychology': 'https://www.bsc.edu/academics/psychology/index.html',\n",
       " 'Economics': 'https://www.bsc.edu/academics/polysci-econ-soc/economics.html',\n",
       " 'Physics': 'https://www.bsc.edu/academics/chem-phy/index.html',\n",
       " 'Education': 'https://www.bsc.edu/academics/education/index.html',\n",
       " 'Religion': 'https://www.bsc.edu/academics/religion/index.html',\n",
       " 'English': 'https://www.bsc.edu/academics/english/index.html',\n",
       " 'Sociology': 'https://www.bsc.edu/academics/polysci-econ-soc/sociology.html',\n",
       " 'Foreign Languages': 'https://www.bsc.edu/academics/mfl/index.html',\n",
       " 'Theatre': 'https://www.bsc.edu/academics/theatre/index.html',\n",
       " 'History': 'https://www.bsc.edu/academics/history/index.html',\n",
       " 'Urban Environmental Studies': 'https://www.bsc.edu/academics/env-studies/index.html'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "department_html = {}\n",
    "\n",
    "for department in department_links:\n",
    "    link = department_links[department]\n",
    "    driver.get(link)\n",
    "    department_html[department] = driver.page_source\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "department_soup = {}\n",
    "\n",
    "for department in department_html:\n",
    "    soup = BeautifulSoup(department_html[department])\n",
    "    department_soup[department] = soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faculty_divs(program_soup):\n",
    "\n",
    "    dropdown = program_soup.find('section', {'class': 'accordion'})\n",
    "\n",
    "    # faculty_drop = dropdown.find('h2', text=re.compile('STAFF|FACULTY|Faculty|Staff')).find_previous('li')\n",
    "\n",
    "    i_tags = dropdown.find_all('i')\n",
    "    for tag in i_tags:\n",
    "        if re.findall('STAFF|FACULTY|Faculty|Staff', tag.find_next('h2').text):\n",
    "            faculty_drop = tag.find_previous('li')\n",
    "\n",
    "    faculty = faculty_drop.find('div', {'class': 'content'}).find_all('p')\n",
    "\n",
    "    return faculty\n",
    "\n",
    "def parse_faculty_no_link(p_tag):\n",
    "    phone = p_tag.find(text = re.compile('\\(.+\\) \\d{3}-\\d{4}|\\d{3}-\\d{3}-\\d{4}'))\n",
    "    if phone:\n",
    "        phone = phone.strip()\n",
    "    email = p_tag.find(text = re.compile('\\@bsc\\.edu'))\n",
    "    return phone, email\n",
    "\n",
    "def scrape_faculty_data(faculty_divs):\n",
    "    data = []\n",
    "    root = 'https://www.bsc.edu/academics/'\n",
    "    for person in faculty_divs:\n",
    "\n",
    "        default = {\"name\": None,\n",
    "                   \"office\": None,\n",
    "                  \"phone\": None,\n",
    "                  \"email\": None,\n",
    "                  \"classes\": None}\n",
    "        name = list(person.strings)\n",
    "        if not name:\n",
    "            continue\n",
    "        if len(name[0]) > 150:\n",
    "            continue\n",
    "        if not name[0].strip():\n",
    "            try:\n",
    "                name = name[1]\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            name = name[0]\n",
    "        default['name'] = name\n",
    "\n",
    "        if person.find('a'):\n",
    "            if person.find('a').attrs['href'][:2] == '..':\n",
    "                href = person.find('a').attrs['href']\n",
    "                faculty_url = root + href.replace('../', '')\n",
    "                driver.get(faculty_url)\n",
    "                faculty_html = driver.page_source\n",
    "                faculty_soup = BeautifulSoup(faculty_html)\n",
    "                try:\n",
    "                    office = faculty_soup.find(text = re.compile(\"Office:\"))\n",
    "                    office = office.find_next('p').text\n",
    "                    default['office'] = office\n",
    "                    phone = faculty_soup.find(text = re.compile(\"Office Phone:\"))\n",
    "                    phone = phone.replace(\"Office Phone:\", '').strip()\n",
    "                    default['phone'] = phone\n",
    "                    email = faculty_soup.find(text=re.compile(\"E-mail:\"))\n",
    "                    email = email.find_next('a').attrs['href'].replace('mailto:', '')\n",
    "                    default['email'] = email\n",
    "                    classes = faculty_soup.find(text=re.compile('Courses Taught:'))\n",
    "                    classes = classes.find_next('blockquote').find_all('strong')\n",
    "                    classes = [x.text for x in classes]\n",
    "                    default['classes'] = classes\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                phone, email = parse_faculty_no_link(person)\n",
    "                default['phone'] = phone\n",
    "                default['email'] = email\n",
    "        data.append(default)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied Computer Science\n",
      "Mathematics\n",
      "Art & Art History\n",
      "Media And Film Studies\n",
      "Biology\n",
      "Music\n",
      "Business\n",
      "Philosophy\n",
      "Chemistry\n",
      "Political Science\n",
      "Classics\n",
      "Psychology\n",
      "Economics\n",
      "Physics\n",
      "Education\n",
      "Religion\n",
      "English\n",
      "Sociology\n",
      "Foreign Languages\n",
      "Theatre\n",
      "History\n",
      "Urban Environmental Studies\n"
     ]
    }
   ],
   "source": [
    "faculty_data = {}\n",
    "\n",
    "for department in department_soup:\n",
    "    print(department)\n",
    "    soup = department_soup[department]\n",
    "    faculty_divs = get_faculty_divs(soup)\n",
    "    data = scrape_faculty_data(faculty_divs)\n",
    "    faculty_data[department] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joel/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: DeprecationWarning: use options instead of chrome_options\n"
     ]
    }
   ],
   "source": [
    "def create_driver(headless=True):\n",
    "    driver = chromedriver_autoinstaller.install(cwd=True)\n",
    "    chrome_options = webdriver.ChromeOptions()     \n",
    "    prefs = {'download.default_directory' : os.getcwd()}\n",
    "    chrome_options.add_experimental_option('prefs', prefs)\n",
    "    if headless:\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "    driver = webdriver.Chrome(driver, \n",
    "                             chrome_options = chrome_options)\n",
    "    return driver\n",
    "\n",
    "def get_department_links(driver):\n",
    "    root = 'https://www.bsc.edu/academics/'\n",
    "    url = root + 'index.html'\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    div = soup.find_all('h2', text=re.compile('Academic Departments'))[0].parent\n",
    "    a_tags = div.find_all('a')\n",
    "    department_links = {a.text: root + a.attrs['href'] for a in a_tags}\n",
    "    \n",
    "    return department_links\n",
    "\n",
    "def get_department_soup(driver, links):\n",
    "\n",
    "    driver.get(link)\n",
    "    html = driver.page_source\n",
    "   \n",
    "    return BeautifulSoup(html)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_faculty_divs(program_soup):\n",
    "\n",
    "    dropdown = program_soup.find('section', {'class': 'accordion'})\n",
    "\n",
    "    # faculty_drop = dropdown.find('h2', text=re.compile('STAFF|FACULTY|Faculty|Staff')).find_previous('li')\n",
    "\n",
    "    i_tags = dropdown.find_all('i')\n",
    "    for tag in i_tags:\n",
    "        if re.findall('STAFF|FACULTY|Faculty|Staff', tag.find_next('h2').text):\n",
    "            faculty_drop = tag.find_previous('li')\n",
    "\n",
    "    faculty = faculty_drop.find('div', {'class': 'content'}).find_all('p')\n",
    "\n",
    "    return faculty\n",
    "\n",
    "\n",
    "def scrape_faculty_data(driver, faculty_divs):\n",
    "    data = []\n",
    "    root = 'https://www.bsc.edu/academics/'\n",
    "    for person in faculty_divs:\n",
    "\n",
    "        default = {\"name\": None,\n",
    "                   \"office\": None,\n",
    "                  \"phone\": None,\n",
    "                  \"email\": None,\n",
    "                  \"classes\": None}\n",
    "        name = list(person.strings)\n",
    "        if not name:\n",
    "            continue\n",
    "        if len(name[0]) > 150:\n",
    "            continue\n",
    "        if not name[0].strip():\n",
    "            try:\n",
    "                name = name[1]\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            name = name[0]\n",
    "        default['name'] = name\n",
    "\n",
    "        if person.find('a'):\n",
    "            if person.find('a').attrs['href'][:2] == '..':\n",
    "                href = person.find('a').attrs['href']\n",
    "                faculty_url = root + href.replace('../', '')\n",
    "                driver.get(faculty_url)\n",
    "                faculty_html = driver.page_source\n",
    "                faculty_soup = BeautifulSoup(faculty_html)\n",
    "                try:\n",
    "                    office = faculty_soup.find(text = re.compile(\"Office:\"))\n",
    "                    office = office.find_next('p').text\n",
    "                    default['office'] = office\n",
    "                    phone = faculty_soup.find(text = re.compile(\"Office Phone:\"))\n",
    "                    phone = phone.replace(\"Office Phone:\", '').strip()\n",
    "                    default['phone'] = phone\n",
    "                    email = faculty_soup.find(text=re.compile(\"E-mail:\"))\n",
    "                    email = email.find_next('a').attrs['href'].replace('mailto:', '')\n",
    "                    default['email'] = email\n",
    "                    classes = faculty_soup.find(text=re.compile('Courses Taught:'))\n",
    "                    classes = classes.find_next('blockquote').find_all('strong')\n",
    "                    classes = [x.text for x in classes]\n",
    "                    default['classes'] = classes\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                phone, email = parse_faculty_no_link(person)\n",
    "                default['phone'] = phone\n",
    "                default['email'] = email\n",
    "        data.append(default)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def parse_faculty_no_link(p_tag):\n",
    "    phone = p_tag.find(text = re.compile('\\(.+\\) \\d{3}-\\d{4}|\\d{3}-\\d{3}-\\d{4}'))\n",
    "    if phone:\n",
    "        phone = phone.strip()\n",
    "    email = p_tag.find(text = re.compile('\\@bsc\\.edu'))\n",
    "    return phone, email\n",
    "\n",
    "def scrape_faculty():\n",
    "    df = pd.DataFrame()\n",
    "    driver = create_driver()\n",
    "    program_links = get_department_links(driver)\n",
    "\n",
    "    for program in program_links:\n",
    "        print(f'Scraping data for {program}')\n",
    "        link = program_links[program]\n",
    "        soup = get_department_soup(driver, link)\n",
    "        divs = get_faculty_divs(soup)\n",
    "        data = scrape_faculty_data(driver, divs)\n",
    "        frame = pd.DataFrame(data)\n",
    "        frame['program'] = program\n",
    "        df = df.append(frame)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joel/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: DeprecationWarning: use options instead of chrome_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Applied Computer Science\n",
      "Scraping data for Mathematics\n",
      "Scraping data for Art & Art History\n",
      "Scraping data for Media And Film Studies\n",
      "Scraping data for Biology\n",
      "Scraping data for Music\n",
      "Scraping data for Business\n",
      "Scraping data for Philosophy\n",
      "Scraping data for Chemistry\n",
      "Scraping data for Political Science\n",
      "Scraping data for Classics\n",
      "Scraping data for Psychology\n",
      "Scraping data for Economics\n",
      "Scraping data for Physics\n",
      "Scraping data for Education\n",
      "Scraping data for Religion\n",
      "Scraping data for English\n",
      "Scraping data for Sociology\n",
      "Scraping data for Foreign Languages\n",
      "Scraping data for Theatre\n",
      "Scraping data for History\n",
      "Scraping data for Urban Environmental Studies\n"
     ]
    }
   ],
   "source": [
    "df = scrape_faculty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>office</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>classes</th>\n",
       "      <th>program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William G. Holt</td>\n",
       "      <td>313 Harbert</td>\n",
       "      <td>(205) 226-4834</td>\n",
       "      <td>wholt@bsc.edu</td>\n",
       "      <td>[UES 110 Sustainability: Southern Cities &amp; The...</td>\n",
       "      <td>Applied Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane Archer</td>\n",
       "      <td>Berte Humanities Building 324</td>\n",
       "      <td>(205) 226-7838</td>\n",
       "      <td>jarcher@bsc.edu</td>\n",
       "      <td>[]</td>\n",
       "      <td>Applied Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Larry Brasher</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>lbrasher@bsc.edu</td>\n",
       "      <td>None</td>\n",
       "      <td>Applied Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scot Duncan</td>\n",
       "      <td>Stephens Science Center 248</td>\n",
       "      <td>(205) 226-4777</td>\n",
       "      <td>sduncan@bsc.edu</td>\n",
       "      <td>[]</td>\n",
       "      <td>Applied Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Andrew Gannon</td>\n",
       "      <td>Stephens Science Center 230</td>\n",
       "      <td>(205) 226-4899</td>\n",
       "      <td>agannon@bsc.edu</td>\n",
       "      <td>[BI 115 Organismal Biology (1), BI 232 Inverte...</td>\n",
       "      <td>Applied Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Megan Gibbons</td>\n",
       "      <td>Stephens Science Center 236</td>\n",
       "      <td>(205) 226-4874</td>\n",
       "      <td>mgibbons@bsc.edu</td>\n",
       "      <td>[BI 115 Organismal Biology (1), BI 225 Evoluti...</td>\n",
       "      <td>Urban Environmental Studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bill Myers</td>\n",
       "      <td>HC 222</td>\n",
       "      <td>(205) 226-4868</td>\n",
       "      <td>bmyers@bsc.edu</td>\n",
       "      <td>[]</td>\n",
       "      <td>Urban Environmental Studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rebekah Parker</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>rpparker@bsc.edu</td>\n",
       "      <td>None</td>\n",
       "      <td>Urban Environmental Studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kathleen Greer Rossmann</td>\n",
       "      <td>Harbert 309</td>\n",
       "      <td>(205) 226-4603</td>\n",
       "      <td>KRossman@bsc.edu</td>\n",
       "      <td>[]</td>\n",
       "      <td>Urban Environmental Studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pete Van Zandt</td>\n",
       "      <td>Stephens Science Center 228</td>\n",
       "      <td>(205) 226-7817</td>\n",
       "      <td>pvanzand@bsc.edu</td>\n",
       "      <td>[BI 101 Explorations in Biology , BI 206 Field...</td>\n",
       "      <td>Urban Environmental Studies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name                         office           phone  \\\n",
       "1           William G. Holt                    313 Harbert  (205) 226-4834   \n",
       "2               Jane Archer  Berte Humanities Building 324  (205) 226-7838   \n",
       "3            Larry Brasher                            None            None   \n",
       "5               Scot Duncan    Stephens Science Center 248  (205) 226-4777   \n",
       "6             Andrew Gannon    Stephens Science Center 230  (205) 226-4899   \n",
       "..                      ...                            ...             ...   \n",
       "8             Megan Gibbons    Stephens Science Center 236  (205) 226-4874   \n",
       "9                Bill Myers                         HC 222  (205) 226-4868   \n",
       "10           Rebekah Parker                           None            None   \n",
       "11  Kathleen Greer Rossmann                    Harbert 309  (205) 226-4603   \n",
       "12           Pete Van Zandt    Stephens Science Center 228  (205) 226-7817   \n",
       "\n",
       "               email                                            classes  \\\n",
       "1      wholt@bsc.edu  [UES 110 Sustainability: Southern Cities & The...   \n",
       "2    jarcher@bsc.edu                                                 []   \n",
       "3   lbrasher@bsc.edu                                               None   \n",
       "5    sduncan@bsc.edu                                                 []   \n",
       "6    agannon@bsc.edu  [BI 115 Organismal Biology (1), BI 232 Inverte...   \n",
       "..               ...                                                ...   \n",
       "8   mgibbons@bsc.edu  [BI 115 Organismal Biology (1), BI 225 Evoluti...   \n",
       "9     bmyers@bsc.edu                                                 []   \n",
       "10  rpparker@bsc.edu                                               None   \n",
       "11  KRossman@bsc.edu                                                 []   \n",
       "12  pvanzand@bsc.edu  [BI 101 Explorations in Biology , BI 206 Field...   \n",
       "\n",
       "                        program  \n",
       "1      Applied Computer Science  \n",
       "2      Applied Computer Science  \n",
       "3      Applied Computer Science  \n",
       "5      Applied Computer Science  \n",
       "6      Applied Computer Science  \n",
       "..                          ...  \n",
       "8   Urban Environmental Studies  \n",
       "9   Urban Environmental Studies  \n",
       "10  Urban Environmental Studies  \n",
       "11  Urban Environmental Studies  \n",
       "12  Urban Environmental Studies  \n",
       "\n",
       "[242 rows x 6 columns]"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['email'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Senate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_current_United_States_senators'\n",
    "response = get(url)\n",
    "soup = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table', {'id':'senators'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Portrait</th>\n",
       "      <th>Senator</th>\n",
       "      <th>Party</th>\n",
       "      <th>Party.1</th>\n",
       "      <th>Born</th>\n",
       "      <th>Occupation(s)</th>\n",
       "      <th>Previous electiveoffice(s)</th>\n",
       "      <th>Education</th>\n",
       "      <th>Assumed office</th>\n",
       "      <th>Term up</th>\n",
       "      <th>Residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Richard Shelby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Republican[2]</td>\n",
       "      <td>(age 87)</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>U.S. HouseAlabama Senate</td>\n",
       "      <td>University of Alabama Birmingham School of Law...</td>\n",
       "      <td>January 3, 1987</td>\n",
       "      <td>2022</td>\n",
       "      <td>Tuscaloosa[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tommy Tuberville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Republican</td>\n",
       "      <td>(age 66)</td>\n",
       "      <td>College football coachPartner, investment mana...</td>\n",
       "      <td>None</td>\n",
       "      <td>Southern Arkansas University</td>\n",
       "      <td>January 3, 2021</td>\n",
       "      <td>2026</td>\n",
       "      <td>Auburn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  Portrait           Senator  Party        Party.1      Born  \\\n",
       "0  Alabama       NaN    Richard Shelby    NaN  Republican[2]  (age 87)   \n",
       "1  Alabama       NaN  Tommy Tuberville    NaN     Republican  (age 66)   \n",
       "\n",
       "                                       Occupation(s)  \\\n",
       "0                                             Lawyer   \n",
       "1  College football coachPartner, investment mana...   \n",
       "\n",
       "  Previous electiveoffice(s)  \\\n",
       "0   U.S. HouseAlabama Senate   \n",
       "1                       None   \n",
       "\n",
       "                                           Education   Assumed office  \\\n",
       "0  University of Alabama Birmingham School of Law...  January 3, 1987   \n",
       "1                       Southern Arkansas University  January 3, 2021   \n",
       "\n",
       "   Term up      Residence  \n",
       "0     2022  Tuscaloosa[3]  \n",
       "1     2026         Auburn  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senate = pd.read_html(str(table))[0]\n",
    "senate.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A better scrape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_senate_table():\n",
    "    \n",
    "    # Connect to the wikipedia page\n",
    "    response = requests.get('https://en.wikipedia.org/wiki/List_of_current_United_States_senators')\n",
    "    # Collect the html from the page\n",
    "    html = response.text\n",
    "    # Parse the html with BeautifulSoup\n",
    "    soup = BeautifulSoup(html)\n",
    "    # Find the senators table\n",
    "    table = soup.find('table', {'id': 'senators'})\n",
    "    \n",
    "    # The first row in the table contains the column names.\n",
    "    # Isolate the first row, then final all of the column tags.\n",
    "    columns = table.find('tr').find_all('th')\n",
    "    # Collect the row tags for the entire dataset\n",
    "    rows = table.find_all('tr')[1:]\n",
    "    # Create an empty list to append the row data to\n",
    "    senate_data = []\n",
    "    # Create some cleaning functions for text data\n",
    "    remove_new_line = lambda x: x.replace('\\n', '')\n",
    "    split_new_line = lambda x: x.split('\\n')\n",
    "    \n",
    "    # Loop over each row\n",
    "    for row in rows:\n",
    "        # find all td tags from the row\n",
    "        td_tags = row.find_all('td')\n",
    "        # ===============================================================================\n",
    "        # The senators table merges the cell for `state name` so it spans both \n",
    "        # senators from a state. \n",
    "        # When parsing the html, the state name only appears for the senator\n",
    "        # that appears first in the table, and the second appearing senator has \n",
    "        # one less td tag.\n",
    "        # Because of this we need to check the length of the td tags\n",
    "        # If there is one less tag, we add  the state name from the previous iteration\n",
    "        # To the beginning of the list of tags\n",
    "        # ===============================================================================\n",
    "        # Check if the list of tags has the full number of columns\n",
    "        if len(td_tags) == len(columns):\n",
    "            # If it does, store the first element in the list of tags\n",
    "            # to a variable called previous_element\n",
    "            previous_element = td_tags[0]\n",
    "        # If the list of tags does not have the full number of columns\n",
    "        # insert the previous_element variable at the beginning of the list of tags\n",
    "        else:\n",
    "            td_tags.insert(0, previous_element)\n",
    "        \n",
    "        # ===============================================================================\n",
    "        #                              Parse the row data\n",
    "        # ===============================================================================\n",
    "        # Collect the state name\n",
    "        state = remove_new_line(td_tags[0].text)\n",
    "        # Collect the image url\n",
    "        image = td_tags[1].find('img').attrs['src']\n",
    "        # Collect the name of the senator\n",
    "        name = remove_new_line(row.find('th').text)\n",
    "        # Collect the css color string for the political party\n",
    "        party_color = td_tags[2].attrs['style'].split(':')[-1]\n",
    "        # Collect the party name\n",
    "        party_name = remove_new_line(td_tags[3].text)\n",
    "        # Collect the date of birth\n",
    "        dob = ' '.join(remove_new_line(td_tags[4]\\\n",
    "                                       .text)\\\n",
    "                                       .strip()\\\n",
    "                                       .split(' ')[1:4])\n",
    "        # Collect the occupation\n",
    "        occupation = split_new_line(BeautifulSoup(str(td_tags[5])\\\n",
    "                                                  .replace('<br/>', '\\n'))\\\n",
    "                                                  .td\\\n",
    "                                                  .text)\n",
    "        # If only one occupation is present\n",
    "        # Pull that occupation out of the list\n",
    "        # And return a single string\n",
    "        if occupation[1] == '':\n",
    "            occupation = occupation[0]\n",
    "        # Collect the previous office\n",
    "        previous_office = split_new_line(BeautifulSoup(str(td_tags[6])\\\n",
    "                                                       .replace('<br/>', '\\n'))\\\n",
    "                                                       .td\\\n",
    "                                                      .text)\n",
    "        # If only one previous office is present\n",
    "        # Pull that value out of the list\n",
    "        # And return a single string\n",
    "        if previous_office[1] == '':\n",
    "            previous_office = previous_office[0]\n",
    "        # Collect assumed office\n",
    "        assumed_office = remove_new_line(td_tags[7].text)\n",
    "        # Collect the end of their term\n",
    "        term_up = remove_new_line(td_tags[8].text)\n",
    "        # Collect their residence\n",
    "        residence = split_new_line(td_tags[9].text)\n",
    "        \n",
    "        # If only one residence is present\n",
    "        # Pull that value out of the list\n",
    "        # And return a single string\n",
    "        if residence[1] == '':\n",
    "            residence = residence[0]\n",
    "            # Many of the residences have a \n",
    "            # link pointing to additional information\n",
    "            # We do not need this\n",
    "            if '[' in residence:\n",
    "                residence = residence[:-3]\n",
    "        # Create data dictionary\n",
    "        collected = {'state': state, 'name': name,'dob': dob, 'party': party_name,\n",
    "                    'party_color': party_color,\n",
    "                    'occupation': occupation,\n",
    "                    'previous_office': previous_office,\n",
    "                    'assumed_office': assumed_office,\n",
    "                    'term_up': term_up, 'residence': residence,\n",
    "                    'portrait': image}\n",
    "        # Append dictionary to the senate_data list\n",
    "        senate_data.append(collected)\n",
    "        \n",
    "    # Once data from all rows has been collected\n",
    "    # return the data as a pandas dataframe\n",
    "    return pd.DataFrame(senate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>party</th>\n",
       "      <th>party_color</th>\n",
       "      <th>occupation</th>\n",
       "      <th>previous_office</th>\n",
       "      <th>assumed_office</th>\n",
       "      <th>term_up</th>\n",
       "      <th>residence</th>\n",
       "      <th>portrait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Richard Shelby</td>\n",
       "      <td>May 6, 1934</td>\n",
       "      <td>Republican[2]</td>\n",
       "      <td>#E81B23</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>[U.S. House, Alabama Senate, ]</td>\n",
       "      <td>University of AlabamaBirmingham School of LawU...</td>\n",
       "      <td>January 3, 1987</td>\n",
       "      <td>2022</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Tommy Tuberville</td>\n",
       "      <td>September 18, 1954</td>\n",
       "      <td>Republican</td>\n",
       "      <td>#E81B23</td>\n",
       "      <td>[College football coach, Partner, investment m...</td>\n",
       "      <td>None</td>\n",
       "      <td>Southern Arkansas University</td>\n",
       "      <td>January 3, 2021</td>\n",
       "      <td>2026</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Lisa Murkowski</td>\n",
       "      <td>May 22, 1957</td>\n",
       "      <td>Republican</td>\n",
       "      <td>#E81B23</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>Alaska House of Representatives</td>\n",
       "      <td>Georgetown UniversityWillamette University Col...</td>\n",
       "      <td>December 20, 2002[d]</td>\n",
       "      <td>2022</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Dan Sullivan</td>\n",
       "      <td>November 13, 1964</td>\n",
       "      <td>Republican</td>\n",
       "      <td>#E81B23</td>\n",
       "      <td>[U.S. Marine Corps officer, Lawyer, Assistant ...</td>\n",
       "      <td>Alaska Attorney General</td>\n",
       "      <td>Culver Military AcademyHarvard UniversityGeorg...</td>\n",
       "      <td>January 3, 2015</td>\n",
       "      <td>2026</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Kyrsten Sinema</td>\n",
       "      <td>July 12, 1976</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>#3333FF</td>\n",
       "      <td>[Social worker, Political activist, Lawyer, Co...</td>\n",
       "      <td>[U.S. House, Arizona Senate, Arizona House of ...</td>\n",
       "      <td>Brigham Young University</td>\n",
       "      <td>January 3, 2019</td>\n",
       "      <td>2024</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Shelley Moore Capito</td>\n",
       "      <td>November 26, 1953</td>\n",
       "      <td>Republican</td>\n",
       "      <td>#E81B23</td>\n",
       "      <td>[College career counselor, Director, state Boa...</td>\n",
       "      <td>[U.S. House, West Virginia House of Delegates, ]</td>\n",
       "      <td>Duke UniversityUniversity of Virginia</td>\n",
       "      <td>January 3, 2015</td>\n",
       "      <td>2026</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Ron Johnson</td>\n",
       "      <td>April 8, 1955</td>\n",
       "      <td>Republican</td>\n",
       "      <td>#E81B23</td>\n",
       "      <td>[Accountant, Corporate executive, ]</td>\n",
       "      <td>None</td>\n",
       "      <td>University of Minnesota</td>\n",
       "      <td>January 3, 2011</td>\n",
       "      <td>2022</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Tammy Baldwin</td>\n",
       "      <td>February 11, 1962</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>#3333FF</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>[U.S. House, Wisconsin Assembly, Dane County, ...</td>\n",
       "      <td>Smith CollegeUniversity of Wisconsin</td>\n",
       "      <td>January 3, 2013</td>\n",
       "      <td>2024</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>John Barrasso</td>\n",
       "      <td>July 21, 1952</td>\n",
       "      <td>Republican</td>\n",
       "      <td>#E81B23</td>\n",
       "      <td>[Orthopedic surgeon, Medical chief of staff, N...</td>\n",
       "      <td>Wyoming Senate</td>\n",
       "      <td>Rensselaer Polytechnic UniversityGeorgetown Un...</td>\n",
       "      <td>June 25, 2007[y]</td>\n",
       "      <td>2024</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Cynthia Lummis</td>\n",
       "      <td>September 10, 1954</td>\n",
       "      <td>Republican</td>\n",
       "      <td>#E81B23</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>[U.S. House, Wyoming Treasurer, Wyoming Senate...</td>\n",
       "      <td>University of Wyoming</td>\n",
       "      <td>January 3, 2021</td>\n",
       "      <td>2026</td>\n",
       "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            state                  name                 dob          party  \\\n",
       "0         Alabama        Richard Shelby         May 6, 1934  Republican[2]   \n",
       "1         Alabama      Tommy Tuberville  September 18, 1954     Republican   \n",
       "2          Alaska        Lisa Murkowski        May 22, 1957     Republican   \n",
       "3          Alaska          Dan Sullivan   November 13, 1964     Republican   \n",
       "4         Arizona        Kyrsten Sinema       July 12, 1976     Democratic   \n",
       "..            ...                   ...                 ...            ...   \n",
       "95  West Virginia  Shelley Moore Capito   November 26, 1953     Republican   \n",
       "96      Wisconsin           Ron Johnson       April 8, 1955     Republican   \n",
       "97      Wisconsin         Tammy Baldwin   February 11, 1962     Democratic   \n",
       "98        Wyoming         John Barrasso       July 21, 1952     Republican   \n",
       "99        Wyoming        Cynthia Lummis  September 10, 1954     Republican   \n",
       "\n",
       "   party_color                                         occupation  \\\n",
       "0      #E81B23                                             Lawyer   \n",
       "1      #E81B23  [College football coach, Partner, investment m...   \n",
       "2      #E81B23                                             Lawyer   \n",
       "3      #E81B23  [U.S. Marine Corps officer, Lawyer, Assistant ...   \n",
       "4      #3333FF  [Social worker, Political activist, Lawyer, Co...   \n",
       "..         ...                                                ...   \n",
       "95     #E81B23  [College career counselor, Director, state Boa...   \n",
       "96     #E81B23                [Accountant, Corporate executive, ]   \n",
       "97     #3333FF                                             Lawyer   \n",
       "98     #E81B23  [Orthopedic surgeon, Medical chief of staff, N...   \n",
       "99     #E81B23                                             Lawyer   \n",
       "\n",
       "                                      previous_office  \\\n",
       "0                      [U.S. House, Alabama Senate, ]   \n",
       "1                                                None   \n",
       "2                     Alaska House of Representatives   \n",
       "3                             Alaska Attorney General   \n",
       "4   [U.S. House, Arizona Senate, Arizona House of ...   \n",
       "..                                                ...   \n",
       "95   [U.S. House, West Virginia House of Delegates, ]   \n",
       "96                                               None   \n",
       "97  [U.S. House, Wisconsin Assembly, Dane County, ...   \n",
       "98                                     Wyoming Senate   \n",
       "99  [U.S. House, Wyoming Treasurer, Wyoming Senate...   \n",
       "\n",
       "                                       assumed_office               term_up  \\\n",
       "0   University of AlabamaBirmingham School of LawU...       January 3, 1987   \n",
       "1                        Southern Arkansas University       January 3, 2021   \n",
       "2   Georgetown UniversityWillamette University Col...  December 20, 2002[d]   \n",
       "3   Culver Military AcademyHarvard UniversityGeorg...       January 3, 2015   \n",
       "4                            Brigham Young University       January 3, 2019   \n",
       "..                                                ...                   ...   \n",
       "95              Duke UniversityUniversity of Virginia       January 3, 2015   \n",
       "96                            University of Minnesota       January 3, 2011   \n",
       "97               Smith CollegeUniversity of Wisconsin       January 3, 2013   \n",
       "98  Rensselaer Polytechnic UniversityGeorgetown Un...      June 25, 2007[y]   \n",
       "99                              University of Wyoming       January 3, 2021   \n",
       "\n",
       "   residence                                           portrait  \n",
       "0       2022  //upload.wikimedia.org/wikipedia/commons/thumb...  \n",
       "1       2026  //upload.wikimedia.org/wikipedia/commons/thumb...  \n",
       "2       2022  //upload.wikimedia.org/wikipedia/commons/thumb...  \n",
       "3       2026  //upload.wikimedia.org/wikipedia/commons/thumb...  \n",
       "4       2024  //upload.wikimedia.org/wikipedia/commons/thumb...  \n",
       "..       ...                                                ...  \n",
       "95      2026  //upload.wikimedia.org/wikipedia/commons/thumb...  \n",
       "96      2022  //upload.wikimedia.org/wikipedia/commons/thumb...  \n",
       "97      2024  //upload.wikimedia.org/wikipedia/commons/thumb...  \n",
       "98      2024  //upload.wikimedia.org/wikipedia/commons/thumb...  \n",
       "99      2026  //upload.wikimedia.org/wikipedia/commons/thumb...  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_senate_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
